# NL2SMT LLM config. Use: smtparser --config this_file, or set NL2SMT_CONFIG to this path.
# See default.conf.example for unified [parser]+[nl2smt]+[solver] config.

[nl2smt]
# provider: optional, used for default base / model name checks (e.g. openai, anthropic)
provider = openai

# model: prefer provider/model form for LiteLLM (e.g. openai/gpt-4o-mini, deepseek/deepseek-chat)
model = openai/gpt-4o-mini

# api_key and api_base: set here (no need to export env)
api_key  = sk-xxxxxxxxxxxxxxxx
api_base =

# Responses API (models with reasoning_content): use_responses, reasoning_effort
use_responses = false
reasoning_effort = medium

# common params
temperature = 0.0
timeout_sec = 90
max_retries = 2

# emit debug to stderr: true/false
debug = false

# prompt paths: relative to this config file's directory, or absolute
# if unset, llm_call.py uses apps/config/prompts/ by default
prompt_file   = prompts/prompt.txt
prompt_plan   = prompts/prompt_plan.txt
prompt_emit   = prompts/prompt_emit.txt
prompt_repair = prompts/prompt_repair.txt
